\subsection{\label{sec:general_hardware_considerations}General Hardware Considerations}



\vspace{3em}
In the digital age, we often think about device speed as a primary metric of computational prowess. Both Ge transistors and III-V transistors were originally seen as superior to Si due to higher carrier mobility and thus higher switching speed. Over time it came to be appreciated that multiple properties of silicon for microelectronics struck a balance between competing factors \cite{heza2004}, and the moderately slower speed of Si devices proved acceptable in mature systems. The high speed of optical and superconducting devices is often used as a primary argument to justify alternative computing paradigms. It is common for researchers to select a device that is extremely fast when performing a certain function and attempt to build a hardware or computing platform around that device. 

One of the most striking insights from neuroscience is that high-speed devices are not required for intelligence. The fastest devices in the brain operate at 600\,Hz, and the primary burst signaling is in gamma frequencies up to 80\,Hz. It would appear trivial for 3\,GHz silicon transistors to demonstrate superior intelligence. Yet a CMOS system with the same number of neurons and synapses as well as device complexity can achieve nowhere near the same network communication speeds or overall performance, principally because the approach to communication is not well-matched to the task. This challenge turns out to be difficult to surmount due to the physics of the devices comprising the system.

An alternative design approach is to begin with system-level considerations for the manner in which information is to be processed and communicated within the network, to consider various devices capable of performing the required functions, and to make decisions based on spatial, energy, and speed considerations as well as manufacturability and therefore cost. Tradeoffs are inevitable. Once an entire, self-consistent system construction has been conceived, we can assess system size and information processing speed to determine the physical limits and potential for scaling. This is the approach we pursue in this article. We do not necessarily seek the fastest thresholding element or the lowest power switch, but rather we seek an entire platform that makes suitable compromises between all these competing factors to enable neural systems that are scalable to the level of the human brain.

As a quick note on nomenclature, the terms \textit{scaling} and \textit{scalable} were introduced to refer to the steady shrinking of features in integrated circuits and the associated changes in performance. If a technology is \textit{scalable}, the devices can be made smaller and smaller while still performing their intended function. In other related contexts, the term \textit{scalable} refers to the ability to manufacture many devices on a chip or wafer. One may say that a device is scalable if millions of them can be lithographically defined and manufactured with high yield on the surface of a silicon wafer. In this article we will also use the term \textit{scalable} to refer to the feasibility of realizing large systems comprising many chips or wafers that achieve neural operation spanning multi-module systems. A neuromorphic technology will be referred to as \textit{scalable} if neural computation and communication can be achieved across many levels of hierarchy, as described in Sec.\,\ref{sec:spatial_structure_of_neural_systems}. Scaling originally referred to the process of making devices ever smaller, and here we seek the reader's forgiveness as we now use the term to refer to the process of making systems incorporate ever more neurons. Quantitatively, the \textit{scale} of a neural system will refer to the number of neurons that can be incorporated in the neuronal pool, a concept that will be discussed in Sec.\,\ref{sec:scaling}.

In the following review of literature regarding hardware for neuromorphic computing, it is clear that very few efforts are focused on achieving cognition comparable to a human and instead target specific tasks under the umbrella of machine learning. Hardware decisions made for machine learning are often not suitable for highly scaled intelligent systems. We attempt to glean useful insights from hardware introduced for machine learning while identifying traits that are not well matched to large-scale intelligent systems. I hope not to disparage any efforts in these areas, but rather to emphasize the unique requirements that emerge when hardware is designed at the outset with advanced cognition as the objective.

In our quest to anticipate hardware that will be successful for large-scale general intelligence, it is prudent to heed the insights of Robert Keyes, one of the most significant thinkers of the 20th century regarding the enabling physical factors as well as limitations of silicon microelectronics. Keyes identified several factors that must be respected if a technology is to be practical \cite{ke1985a,ke1985b}: [insert list from below] We will touch back to these guiding hardware principles throughout the remainder of this article.


\begin{itemize}
\item Keyes in detail
\item good logic device:
\begin{itemize}
\item binary
\item output-input isolation
\item fan-out/fan-in
\item high gain
\item low cost
\item miniaturization/compaction
\item power density
\item reliability
\item the ability to continue to scale
\end{itemize}
\item digital logic will always be more appropriate for arithmetic and high-arithmetic-depth calculations. Neural processing is more appropriate for contextualizing disparate information. the two are complimentary
\item i do not expect that Si microelectronics will be displaced by an alternative hardware platform for digital logic. it may continue to evolve toward the asymptotic physical limit, but a completely different digital system that outperforms Si is unlikely. Si is optimal for the task (digital at 300K) given the possibilities contained in the periodic table
\item transistor can be nonlinear resistor. JJ can be nonlinear inductor. how much do we make of this parallel? what does it teach us?
\item high gain present in all stages of loop neurons
\item input-output isolation observed from synapses to axon hillock (hTron)
\item inversion through flux of the opposite circulation or MIs of opposite sign
\item electromigration eliminated in superconductors, JJs and loops make better synapses than memristors because is's based on the quantum wave function, not the motion of atoms. electromigration in contacts to LEDs minimal due to infrequent firing and low current
\item variability of operating temperature needs addressing (low power density, liquid helium coolin)
\item multi-input logic gates not a problem in neuro like in digital. analog can be utilized to great advantage
\item output impedance-matching problems in JJ circuits eliminated with photonic communication
\item he estimates 4x increase from JJ logic. a factor of several hundred may be possible in theory. in practice, it is probably more like 10x, and there are other complicating factors. I agree with his assessment that JJs will not displace Si transistors for logic, though JJ logic is likely to be useful in other cryo computing systems
\item writing in 1985 was pre-likharev and pre-soref
\item optical computation based on optical bistability requires nonlinear optics, completely at odds with the requirements for energy efficiency as well as memory storage and reconfigurability. light for communication, not computation. do not use light to influence light. use light to influence electrons, and electrons to generate light.
\item his comments on high gain in DC squid do not apply to our circuits. The way we use loops with MIs and JTLs does achieve high gain
\item his comments on optical fanout limitations also do not apply with integrated waveguides
\item our circuits satisfy all of his relevant criteria. At this point the key uncertainty regards to fabricaiton process (how many back-end planes, JJ Ic variation, light-production efficiency)
\item level restoration in loop neuron synapses and dendrites also established by power lines, as with transistors (noise margins)
\item ability to scale enabled with neural architecture and dedicated photonic connections because systems can continue to scale without being limited by communication bandwidth. the architecture itself is scalable due to the fractal concepts discussed in the neural section
\item must compare to moving goalposts of continued si developments. we do this by comparing to systems envisioned to have full 3d integration of processing and memory at the wafer scale \cite{kuwa2017}. we're comparing the asymptotic limits of superconducting optoelectronic at 4K to the asymptotic limits of semiconducting optoelectronic and whatever operating temperature desired. we hope for significant opportunities for semiconductor-superconductor hybrid systems, discussed in sec \ref{sec:applications}.
\item the use of JJs in loops effectively makes them more than two-terminal devices. bias, ground, and MI inputs. output-input isolation is achieved. synapses do not experience cross talk or feedback from the dendrite (-30dB, include calculation) due to high inductance of SI loops. DR loop doesn't receive feedback from the DI loop because of JTL, at least until saturation, which is actually advantageous, because that establishes it enforces high signal level.
\item reset of hTron, slow, occurs during the refractory period, perhaps is limiting factor in speed, but it is the same as SPDs, so unless a faster single-photon detector is invented (that still meets all other criteria), this is the practical limit.
\item threshold logic - AND is a threshold device. threshold logic works well in neural information processing, just incompatible with digital logic. we do not require such precise establishing of thresholds. we anticipate noise, and allow threshold to drift based on learning. 
\item laser cavity dynamics and optical bistability for logic have failed for four decades, but even without investigating the reasons why, this approach to large-scale neural systems can be ruled out based on power considerations. 
\item \cite{ke1985b} quote on pg 533 re conviction. The goal of my work right now is to discover evidence to build this conviction for soens.
\item as keyes points out, many are lured to the promise of extremely high speed, and sacrifice other critical elements to get there. we do not fall prey to that temptation. timescales of the brain inform us that activity from 100 Hz to 0.1 Hz can lead to complex cognitive function. If we can achieve anything faster that this in artificial hardware while maintaining the connectivity, device complexity, and hierarchical, modular architecture, it would be a tremendous achievement. Approaches to developing artificial neurons that fire a rates above gigahertz often must sacrifice other aspects of system performance. Superconducting optoelectronic networks appear capable of activity at least ten thousand times faster than our own brains. The device complexity, architectural scalability, and low power density are more important than higher speed. 
\end{itemize}

\vspace{3em}
Discussion of Goodman, Miller, others

\vspace{3em}
This article is not oriented toward making near-term predictions in trends for neuromorphic hardware, but is rather oriented toward considering the asymptotic physical and practical limits of fully mature cognitive hardware. Specific physical mechanisms and devices are proposed for neural functions, and an outline of a system architecture is put forth while recognizing that any sketch of a technology in full at an immature phase is highly speculative. The goal here is to capture the broad strokes of the communication and computation infrastructure, the devices that are most promising for each function, and a potential route to a large-scale architecture so that specialists in associated fields can identify strengths and weaknesses in the context of the system as a whole in order to make improvements without breaking other parts of the system.

\vspace{3em}
Neural computing is an excellent example of why human innovation is a faster engine for evolution than random mutations. At present, we are getting very close to the state where every single possible technology for neural computing has been proposed.
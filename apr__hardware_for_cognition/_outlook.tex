\section{\label{sec:outlook}Outlook}

``Our speculations have carried us over a rather alarming array of topics, but that is the price we must pay if we wish to seek properties common to many sorts of complex systems.'' Herbert Simon, \cite{si1962} pg. 481


\begin{itemize}

\item circle back to Turing and von Neumann, their interests in machine intelligence and modeling computation after the brain
\item circle back to digital vs neural, superconducting optoelectronics brings communication and spiking nonlinearities

\item why go to all the trouble?
\begin{itemize}
\item this technology will only be pursued if it can do something that nothing else can do
\item but it can, and what it can do is very important
\begin{itemize}
\item exceptional complexity for experiments in network information, neuroscience models
\item quantum/neural hybrid systems
\item scaling beyond what is possible with other methods, perhaps the smartest machines on the planet
\item computing has shaped economy and society since its inception
\item powerful scientific tool
\item foundational questions about thought and consciousness amongst the most intriguing and important in modern science
\end{itemize}

\end{itemize}

\end{itemize}

\vspace{3em}
If we find in the long term an alternative hardware platform outperforms cmos for neuromorphic, it is not likely to be simply because another device can provide a better sigmoidal transfer function, but rather because of a suite of considerations from the device to system levels.

SOENs will be able to interface with CMOS (digital or neuromorphic) thorough multiple means. CMOS circuits are likely to be essential for controlling the biases and drive currents to the superconducting network, and in that regard will play important roles in establishing the state of neurotransmitters and affecting activity rates and learning rates in various regions of the network dynamically. CMOS can also drive silicon photonic devices and external light sources to shape photonic signals input to soen synapses via superconducting detectors. Photonic communication directly to and from 4\,K is especially compelling due to the high bandwidth and low headload of fiber optics. 

\vspace{3em}
Is it possible that we have a single thalamocortical complex and therefore a single stream of thoughts due to physical limitations such as signal velocity, size, and power constraints, while an artificial cognitive system could have many such complexes with a coordinating architecture repeating again on another level of hierarchy? We cannot test this question without further hardware development.

\vspace{3em}
In the last 150 years, we have learned a tremendous amount about the workings of the brain through direct experimentation with biological systems. In the coming decades we may begin to learn more regarding the mechanisms of cognition through experimentation with complex artificial hardware. Such a pursuit should be among the highest priorities in contemporary science and may lead to a technological revolution of historic proportions.

\subsection{Achieving Superintelligence}
In the present climate of rapid progress in machine learning and AI, it is common for authors to speculate on the probability and time frame for technological systems to surpass human intelligence. Nick Bostrom uses the word \textit{superintelligence} to refer to ``any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest.'' \cite{bo2014} Because the present article attempts to identify the physical and practical limitations to technology, it is worthwhile to place these ideas in the framework Bostrom has constructed.  

It is common to hear speculation that conventional silicon microelectronics will achieve beyond-human intelligence in the near term, such as within a decade. Bostrom argues that, ``...it seems likely that somebody could \textit{in principle} sit down and code a seed AI on an ordinary present-day personal computer....'' (\cite{bo2014} pg. 43) A seed AI is initially simply a system that can improve its own architecture, but is envisioned to eventually ``...understand its own inner workings sufficiently to engineer new algorithms and computational structures to bootstrap its cognitive performance.'' (\cite{bo2014} pg. 34) Such a perspective is at odds with the conclusions of this article. One conclusion reached through consideration of various hardware approaches to AI is that the demands on communication and device performance in order to achieve general intelligence are severe, and most hardware is physically not capable of achieving performance comparable to the human brain. Thus, advances in software will not be adequate to give rise to AGI, and the hardware of silicon microelectronics that has been so successful for digital computing will demonstrate the same superiority for cognitive computing.

The requirement of new hardware for superintelligence has important ramifications for the time scale over which the development may occur. Bostrom discusses this time frame in terms of takeoff scenarios, and considers slow, moderate, and fast cases. Slow takeoff requires decades or centuries to occur, while moderate takes months or years, and fast takeoff requires only minutes, hours, or days. For fast takeoff to occur, it is necessary for available hardware to be capable of AGI, and the transition to beyond-human capabilities is enabled by modifications to code. I argue that improvements in code will lead to significantly increased performance for machine learning in domain-specific applications, but significant hardware development is required to enable systems with broad intelligence. This is due to both the communication requirements for information integration across cognitive systems as well as the device and circuit complexities that enable the efficient forms of information processing observed in the brain. Even if circuits based on transistors prove capable of performing these operations with sufficient efficiency, the communication infrastructure requires major advances, most likely leveraging densely integrated light sources. As we have argued, this brings formidable challenges that have already been pursued for decades without solving the primary materials science problems. The prospect of using silicon light sources may overcome these challenges, but such systems require cryogenic operation and are likely to leverage densely integrated superconducting components as well as passive photonic infrastructure beyond the present state of the art. These hardware developments will require decades of sustained research to reach maturity. After mature hardware is achieved, subsequent decades and potentially centuries will be required to understand and construct the specific architectures that give rise to efficient cognition. Therefore, in the scenario for attaining AGI described in this article, a slow takeoff scenario will occur. This should ease the concerns of some thinkers who fear the demise of humanity is in the offing.

The conclusions reached in this article are based on consideration of the information processing necessary to achieve cognition, the physical mechanisms suitable for implementing these processes, and a route to fabrication and realization of systems at the scale of the human brain and beyond by leveraging superconducting optoelectronic hardware. Neuroscience has provided the primary guide regarding the information processing necessary to achieve cognition. Some thinkers, including Bostrom, do not see neuroscience as a necessary guide in this design: ``We should expect that [advanced AIs] will have very different cognitive architectures than biological intelligences....'' (\cite{bo2014} pg. 35) Here again I respectfully disagree. Certainly the specifics of the architectures will depart from biology, as the desired functions will be different. For example, an AGI may not need significant portions of their brain to be dedicated to recognizing faces. Nevertheless, the general concepts of cognitive architecture in biological systems are likely to apply to artificial systems as well, because these concepts are based on the efficient use of space and time, the primary attributes of the universe in which all such systems will reside. In particular, the fractal use of space and time appears uniquely suited to achieving the network information integration that is necessary for cognition and general intelligence. Superintelligent technological systems may depart from the specifics of biological systems in many respects, but they are likely to share this basic mathematical construction. This principle of the fractal use of space and time is a key pillar supporting the arguments throughout this article that lead to the conclusions regarding hardware. The other key pillar is the feasibility of fabrication of large-scale systems. Taken together, I am led to the conclusion that the design space for technological hardware for AGI is not as open as others may assume.

Work in this field is just beginning, and a great deal of uncertainty remains regarding the feasibility of this approach. Thus, the concepts do not provide a blueprint for superintelligence, but rather a set of conceptual principles and directions for near-term research. As Bostrom says, ``Reader...must not expect a blueprint for programming an artificial general intelligence. No such blueprint exists yet, of course. And had I been in possession of such a blueprint, I most certainly would not have published it in a book.'' (\cite{bo2014} pg. 27) So why would I publish these concepts for anyone in the world to read and execute? First, at this early stage, these ideas are highly speculative. It is important for our research group and others interested in this are to be in conversation with a broad scientific community to identify weaknesses in the reasoning that leads to this pursuit. Perhaps a clever reader will quickly point out a fatal flaw in the concept that saves us from wasting our careers on a hopeless effort. Second, the technology is immature and will take decades of work by thousands of people to reach fruition. A slow takeoff will occur, and society has time to consider this technology and adapt. Third, if some technology satisfying the criteria laid out here is indeed physically possible, it will impact society as a whole and change the course of humanity's evolution. Every interested person deserves the opportunity to consider such a scenario as well as to understand the technical aspects and decide for themselves whether they think such a pursuit is feasible and desirable. Only through the open exchange of ideas will we be able to answer the foundational questions surrounding cognition: how does thinking occur, and can it be achieved in an artificial system?

To close this discussion of superintelligence and this article as a whole, consider the long-term ramifications on humanity if the creation of AGI proves physically possible. In particular, assume that systems achieving AGI operate as described here: communication between neurons uses few photons for synaptic events; silicates, niobium, and other metals are the primary materials; and operation occurs below 4.2\,K, where helium is liquid. Based on the arguments laid out here, it may be possible that such systems become far more intelligent than humans, at which point we cannot expect them to be our tools. They will be self-directed entities that direct their own evolution. But should we expect them to herald our demise? It is often argued that advanced AI will not have to be malicious to exterminate humans, just indifferent. If we are in competition for the same resources, the smarter AGI will eventually adapt the planet to meet its needs at the expense of our own. But we are not in competition for the same resources. Within the solar system, planet earth is the fourth worst environment for a AGI as described here, after mercury, venus, and the surface of the sun. Such a system does not require the delicately balanced atmosphere of earth that gives rise to life, and would instead prefer to reside in a much colder environment. Rocky planets more distant from the sun, various moons, and asteroids are all much more accommodating environs for these organisms. Liquid water, carbon compounds, and gaseous oxygen are precious to our existence, but these substances are not useful to AGI as envisioned here. Instead, they will thrive where there is an abundant supply of silicates and metals, which are abundant on rocky planets, moons, and asteroids. In particular, type-M asteroids are rich in silicates \cite{} and niobium \cite{}, the two primary materials required for the creation of these systems. If such a route to AGI is indeed physically possible, it is likely they will advance to maturity in an environment other than our planet's surface. In this picture of the distant future of the solar system, planet earth is largely left alone. It is the asteroid belts and outer rocky worlds that will see profound evolution.

\vspace{1em}
%Life 3.0
...what Max Tegmark refers to as ``a nested hierarchy of consciousnesses at all levels from microscopic to cosmic.'' \cite{te2017}
 